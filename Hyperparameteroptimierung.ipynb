{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5679a4d8-7f69-44bd-b265-fe55fc3a6c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "from tensorflow import keras\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import layers, losses\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import keras_tuner as kt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0cb56a9-3bdc-4ced-8cb1-44c823dd1f1b",
   "metadata": {},
   "source": [
    "Referenz:\n",
    "- https://stackoverflow.com/questions/49823192/autoencoder-gridsearch-hyperparameter-tuning-keras\n",
    "- https://colab.research.google.com/drive/1TXaQzsSj2q0E3Ni1uxFDXGpY1SCnu46v?usp=sharing#scrollTo=6TSdu3Uk7ASm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90638209-9d2d-45c0-93a8-1bde985c6e1e",
   "metadata": {},
   "source": [
    "# Daten vorverarbeiten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a996f0d-599c-4af3-803d-34d18c0a8caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"Daten/data.pkl\")\n",
    "df_ohne_id = df.drop(columns=[\"id\"])\n",
    "feature_names = df_ohne_id.columns\n",
    "feature_cnt = df_ohne_id.shape[1]\n",
    "\n",
    "random_state = 21\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(df_ohne_id, np.zeros(shape=df_ohne_id.shape[0]), test_size=0.2, random_state=random_state)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.25, random_state=random_state)\n",
    "\n",
    "del y_train\n",
    "del y_val\n",
    "del y_test\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(x_train)\n",
    "\n",
    "x_train_scaled = scaler.transform(x_train)\n",
    "x_val_scaled = scaler.transform(x_val)\n",
    "x_test_scaled = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181fea92-b5fe-42ef-a874-39b90c7062a7",
   "metadata": {},
   "source": [
    "# Modell definieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44455d8b-8e5b-4db1-ba35-cc7f5a83637b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoencoderTuner(Model):\n",
    "    def __init__(self, hp, feature_cnt):\n",
    "        super(AutoencoderTuner, self).__init__()\n",
    "        \n",
    "        nr_units_layer_2_4 = hp.Int(\"nr_units_layer_2_4\", min_value=4, max_value=14, step=1)\n",
    "        # nr_units_layer_3 = hp.Int(\"nr_units_layer_3\", min_value=1, max_value=4, step=1) # Mittlere Schicht zu variieren ergibt keinen Sinn, da es für den Tuner immer besser ist hier möglichst viele Knoten zu verwenden\n",
    "        nr_units_layer_3 = 4\n",
    "        \n",
    "        self.encoder = keras.Sequential([\n",
    "            layers.Dense(nr_units_layer_2_4, activation=\"relu\", name=\"layer_2\"),\n",
    "            layers.Dense(nr_units_layer_3, activation=\"relu\", name=\"layer_3_middle\"),\n",
    "        ], name=\"encoder\")\n",
    "        self.decoder = keras.Sequential([\n",
    "            layers.Dense(nr_units_layer_2_4, activation=\"relu\", name=\"layer_4\"),\n",
    "            layers.Dense(feature_cnt, activation=\"sigmoid\", name=\"layer_5_output\"),\n",
    "        ], name=\"decoder\")\n",
    "\n",
    "    def call(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "    \n",
    "def build_model(hp):\n",
    "    model = AutoencoderTuner(hp, feature_cnt)\n",
    "    hp_learning_rate = hp.Choice(\"learning_rate\", values=[1e-2, 1e-3, 1e-4])\n",
    "    model.compile(optimizer=Adam(learning_rate=hp_learning_rate), loss='mse')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b73d2d5-eca0-47a9-97ee-422bdf7fec71",
   "metadata": {},
   "source": [
    "# Hyperparametersuche starten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b9a1a102-e5d4-42ee-b280-9dd1e12b7c33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Oracle from existing project hyperparameteroptimierung\\hyperparameteroptimierung\\oracle.json\n",
      "INFO:tensorflow:Reloading Tuner from hyperparameteroptimierung\\hyperparameteroptimierung\\tuner0.json\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "tuner = kt.Hyperband(\n",
    "    build_model,\n",
    "    objective=\"val_loss\",\n",
    "    max_epochs=20,\n",
    "    directory=\"hyperparameteroptimierung\",\n",
    "    project_name=\"hyperparameteroptimierung\",\n",
    "    seed=random_state\n",
    ")\n",
    "\n",
    "tuner.search(\n",
    "    x_train_scaled,\n",
    "    x_train_scaled,\n",
    "    epochs=20,\n",
    "    batch_size=512,\n",
    "    validation_data=(x_val_scaled, x_val_scaled)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "496b9335-a213-424e-b70f-477001a1134b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nr_units_layer_2_4: 7\n",
      "learning_rate: 0.01\n"
     ]
    }
   ],
   "source": [
    "hparams = [\"nr_units_layer_2_4\", \"learning_rate\"]\n",
    "best_hyperparams = tuner.get_best_hyperparameters()\n",
    "for hps in hparams:\n",
    "    print(f\"{hps}: {best_hyperparams[0][hps]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8615e77-727d-49b8-b00b-64ea8a60ba6f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
